{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "843ba57d-8061-4596-a5cb-0639d34e200b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## promptmanteau\n",
    "port·man·teau is a word blending the sounds and combining the meanings of two others, for example motel (from ‘motor’ and ‘hotel’) or brunch (from ‘breakfast’ and ‘lunch’)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a97b17a-c94a-4b47-b926-a533b6454eb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "Mechanistic Intepretability project <br>\n",
    "for [Apart Research #4 Hackathon](https://itch.io/jam/mechint) by [Mentaleap](https://mentaleap.ai/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd759a61-4641-476a-8553-b4629c5580e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45ad159e-fca5-42b0-91e5-5ec0f373b297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: --no-binary currently disables reading from the cache of locally built wheels. In the future --no-binary will not influence the wheel cache. pip 23.1 will enforce this behaviour change. A possible replacement is to use the --no-cache-dir option. You can use the flag --use-feature=no-binary-enable-wheel-cache to test the upcoming behaviour. Discussion can be found at https://github.com/pypa/pip/issues/11453\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: numpy in ./.pyenv/versions/3/lib/python3.10/site-packages (1.23.4)\n",
      "\u001b[33mDEPRECATION: --no-binary currently disables reading from the cache of locally built wheels. In the future --no-binary will not influence the wheel cache. pip 23.1 will enforce this behaviour change. A possible replacement is to use the --no-cache-dir option. You can use the flag --use-feature=no-binary-enable-wheel-cache to test the upcoming behaviour. Discussion can be found at https://github.com/pypa/pip/issues/11453\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: matplotlib in ./.pyenv/versions/3/lib/python3.10/site-packages (3.6.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.pyenv/versions/3/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.pyenv/versions/3/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.pyenv/versions/3/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./.pyenv/versions/3/lib/python3.10/site-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in ./.pyenv/versions/3/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.pyenv/versions/3/lib/python3.10/site-packages (from matplotlib) (1.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.pyenv/versions/3/lib/python3.10/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: numpy>=1.19 in ./.pyenv/versions/3/lib/python3.10/site-packages (from matplotlib) (1.23.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.pyenv/versions/3/lib/python3.10/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.pyenv/versions/3/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mDEPRECATION: --no-binary currently disables reading from the cache of locally built wheels. In the future --no-binary will not influence the wheel cache. pip 23.1 will enforce this behaviour change. A possible replacement is to use the --no-cache-dir option. You can use the flag --use-feature=no-binary-enable-wheel-cache to test the upcoming behaviour. Discussion can be found at https://github.com/pypa/pip/issues/11453\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch in ./.pyenv/versions/3/lib/python3.10/site-packages (1.13.1)\n",
      "Requirement already satisfied: typing-extensions in ./.pyenv/versions/3/lib/python3.10/site-packages (from torch) (4.4.0)\n",
      "\u001b[33mDEPRECATION: --no-binary currently disables reading from the cache of locally built wheels. In the future --no-binary will not influence the wheel cache. pip 23.1 will enforce this behaviour change. A possible replacement is to use the --no-cache-dir option. You can use the flag --use-feature=no-binary-enable-wheel-cache to test the upcoming behaviour. Discussion can be found at https://github.com/pypa/pip/issues/11453\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tqdm in ./.pyenv/versions/3/lib/python3.10/site-packages (4.64.1)\n",
      "\u001b[33mDEPRECATION: --no-binary currently disables reading from the cache of locally built wheels. In the future --no-binary will not influence the wheel cache. pip 23.1 will enforce this behaviour change. A possible replacement is to use the --no-cache-dir option. You can use the flag --use-feature=no-binary-enable-wheel-cache to test the upcoming behaviour. Discussion can be found at https://github.com/pypa/pip/issues/11453\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: datasets in ./.pyenv/versions/3/lib/python3.10/site-packages (2.8.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in ./.pyenv/versions/3/lib/python3.10/site-packages (from datasets) (2022.11.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./.pyenv/versions/3/lib/python3.10/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: packaging in ./.pyenv/versions/3/lib/python3.10/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: responses<0.19 in ./.pyenv/versions/3/lib/python3.10/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.pyenv/versions/3/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: dill<0.3.7 in ./.pyenv/versions/3/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./.pyenv/versions/3/lib/python3.10/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.pyenv/versions/3/lib/python3.10/site-packages (from datasets) (1.23.4)\n",
      "Requirement already satisfied: xxhash in ./.pyenv/versions/3/lib/python3.10/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in ./.pyenv/versions/3/lib/python3.10/site-packages (from datasets) (0.11.1)\n",
      "Requirement already satisfied: aiohttp in ./.pyenv/versions/3/lib/python3.10/site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: pandas in ./.pyenv/versions/3/lib/python3.10/site-packages (from datasets) (1.5.1)\n",
      "Requirement already satisfied: multiprocess in ./.pyenv/versions/3/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in ./.pyenv/versions/3/lib/python3.10/site-packages (from datasets) (10.0.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./.pyenv/versions/3/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.pyenv/versions/3/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.pyenv/versions/3/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.pyenv/versions/3/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.pyenv/versions/3/lib/python3.10/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.pyenv/versions/3/lib/python3.10/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in ./.pyenv/versions/3/lib/python3.10/site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: filelock in ./.pyenv/versions/3/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.pyenv/versions/3/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./.pyenv/versions/3/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.pyenv/versions/3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.pyenv/versions/3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.pyenv/versions/3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.12)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.pyenv/versions/3/lib/python3.10/site-packages (from pandas->datasets) (2022.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.pyenv/versions/3/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.pyenv/versions/3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "\u001b[33mDEPRECATION: --no-binary currently disables reading from the cache of locally built wheels. In the future --no-binary will not influence the wheel cache. pip 23.1 will enforce this behaviour change. A possible replacement is to use the --no-cache-dir option. You can use the flag --use-feature=no-binary-enable-wheel-cache to test the upcoming behaviour. Discussion can be found at https://github.com/pypa/pip/issues/11453\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in ./.pyenv/versions/3/lib/python3.10/site-packages (4.24.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.pyenv/versions/3/lib/python3.10/site-packages (from transformers) (1.23.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.pyenv/versions/3/lib/python3.10/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in ./.pyenv/versions/3/lib/python3.10/site-packages (from transformers) (0.11.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.pyenv/versions/3/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: filelock in ./.pyenv/versions/3/lib/python3.10/site-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./.pyenv/versions/3/lib/python3.10/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.pyenv/versions/3/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: requests in ./.pyenv/versions/3/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.pyenv/versions/3/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.pyenv/versions/3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./.pyenv/versions/3/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./.pyenv/versions/3/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.pyenv/versions/3/lib/python3.10/site-packages (from requests->transformers) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.pyenv/versions/3/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.pyenv/versions/3/lib/python3.10/site-packages (from requests->transformers) (2022.9.24)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install torch\n",
    "!pip install tqdm\n",
    "!pip install datasets\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea507aab-bcb6-4608-87b4-d84e6510045c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99b4010a-667e-4999-a3db-1aaeed9fe6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itay/.pyenv/versions/3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "import re\n",
    "import itertools\n",
    "    \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast, LogitsProcessor, LogitsProcessorList, LogitsWarper\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf49d834-16de-4ad3-b5f0-7ac0d7e6fdbf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Lib"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a1db6e9-a88b-4d7a-a2f1-4cea4eead609",
   "metadata": {},
   "source": [
    "General idea is to set aside some tokens (n_tokens) that will be optimized to encode 'task-embedding'\n",
    "It is done by overriding the forward() function of the Embedding phase of the model\n",
    "The new tokens named \"learned_embedding\" are concatinated before the input embedding \n",
    "We skip the first n_tokens tokens of the input and effectivly replacing them with our learned params.\n",
    "This requires the input to be padded with n_tokens tokens\n",
    "In the code we see the following line:\n",
    "    torch.full((1, n_tokens), 50256)\n",
    "It is responsible for adding n_tokens [end-of-text] tokens at the begging of the input!\n",
    "This code was taken from: https://github.com/kipgparker/soft-prompt-tuning\n",
    "and is based on Google-Research paper: 'The Power of Scale for Parameter-Efficient Prompt Tuning'\n",
    "    https://arxiv.org/abs/2104.08691"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8662952-8e69-4a17-b059-3549cbc5df41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftEmbedding(nn.Module):\n",
    "    def __init__(self, \n",
    "                wte: nn.Embedding,\n",
    "                n_tokens: int = 10, \n",
    "                random_range: float = 0.5,\n",
    "                initialize_from_vocab: bool = True):\n",
    "        super(SoftEmbedding, self).__init__()\n",
    "        self.wte = wte\n",
    "        self.n_tokens = n_tokens\n",
    "        self.learned_embedding = nn.parameter.Parameter(self.initialize_embedding(wte,\n",
    "                                                                               n_tokens, \n",
    "                                                                               random_range, \n",
    "                                                                               initialize_from_vocab))\n",
    "    def initialize_embedding(self, \n",
    "                             wte: nn.Embedding,\n",
    "                             n_tokens: int = 10, \n",
    "                             random_range: float = 0, \n",
    "                             initialize_from_vocab: bool = True):\n",
    "        \"\"\"initializes learned embedding\n",
    "\n",
    "        Args:\n",
    "            same as __init__\n",
    "\n",
    "        Returns:\n",
    "            torch.float: initialized using original schemes\n",
    "        \"\"\"\n",
    "        if initialize_from_vocab:\n",
    "            return self.wte.weight[:n_tokens].clone().detach()\n",
    "            \n",
    "        return torch.FloatTensor(n_tokens, wte.weight.size(1)).uniform_(-random_range, random_range)\n",
    "            \n",
    "    def forward(self, tokens):\n",
    "        \"\"\"run forward pass\n",
    "\n",
    "        Args:\n",
    "            tokens (torch.long): input tokens before encoding\n",
    "\n",
    "        Returns:\n",
    "            torch.float: encoding of text concatenated with learned task specifc embedding\n",
    "        \"\"\"\n",
    "        input_embedding = self.wte(tokens[:, self.n_tokens:])\n",
    "        learned_embedding = self.learned_embedding.repeat(input_embedding.size(0), 1, 1)\n",
    "        return torch.cat([learned_embedding, input_embedding], 1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cb515bd3-6608-4767-8d11-4bc6ac6fcf2a",
   "metadata": {},
   "source": [
    "We were inspired by \"Speaking Probes\" to explore task vectors/tokens:\n",
    "\n",
    "- https://towardsdatascience.com/speaking-probes-self-interpreting-models-7a3dc6cb33d6\n",
    "- https://github.com/guyd1995/speaking-probes \n",
    "\n",
    "This library is able to add word-tokens <neuron> that will be replaced with a specific vector after the embedding phase.\n",
    "Then we use the model to generate text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e6ead6-289b-4d71-8440-d9be9d866816",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Init Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4099e8a9-888c-4713-b74c-61099fd4c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading gpt2 model\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e30c65d1-d867-44af-bae5-c2bf25b6a8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing the model\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1530ba3-8961-43ff-b5ef-dfbe00bfbd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overriding model embedding layer\n",
    "n_tokens = 1\n",
    "initialize_from_vocab = False\n",
    "\n",
    "current_embedding = deepcopy(model.get_input_embeddings())\n",
    "s_wte = SoftEmbedding(current_embedding, n_tokens=n_tokens, initialize_from_vocab=initialize_from_vocab)\n",
    "\n",
    "model.set_input_embeddings(s_wte)\n",
    "params_before_training = deepcopy(s_wte.learned_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd396be8-6605-4d51-8a06-b3dc3c926489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, tokenizer, query):\n",
    "    inputs = tokenizer(query, return_tensors=\"pt\")\n",
    "    \n",
    "    end_of_text_padding = torch.full((1, n_tokens), 50256)\n",
    "    inputs['input_ids'] = torch.cat([end_of_text_padding, inputs['input_ids']],  dim=1)\n",
    "    ones = torch.full((1, n_tokens), 1)\n",
    "    inputs['attention_mask'] = torch.cat([ones, inputs['attention_mask']], dim=1)\n",
    "    \n",
    "    return model(**inputs).logits[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143b5a0f-f19f-4b5e-bafc-1d3f40ddba8a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Task Definition / Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1823f69-75f4-4462-9b83-bd78218f911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our dataset is comprised of the numbers 0-500.\n",
    "# Our task is +1\n",
    "# Each of these numbers is encoded with a single token (useful for task simplicity) \n",
    "# We sample 100 numbers from this range and fit the task-token to correspond for +1.\n",
    "# label_ids a dict:\n",
    "    # matches query (number in range 0-500) with answer (the number+1).\n",
    "# identity_label_ids:\n",
    "    # # matches query (number in range 0-500) with answer (the same number).\n",
    "    \n",
    "dataset = np.random.randint(500, size=(100,))\n",
    "evalset  = list(range(500))\n",
    "\n",
    "plus_two_task = {i: tokenizer.encode(str(i+2))[0] for i in range(500)}\n",
    "plus_one_task = {i: tokenizer.encode(str(i+1))[0] for i in range(500)}\n",
    "identity_task = {i: tokenizer.encode(str(i))[0] for i in range(500)}\n",
    "\n",
    "format_query = lambda x: f\"{x},\"\n",
    "\n",
    "def only_relevant_logits(logits, task_mapping):\n",
    "    '''\n",
    "        task_mapping: maps between inputs to f(inputs)\n",
    "        returns list of predictions with indices corresponding to the INPUT, and values corresponding to the OUTPUT\n",
    "        meaning that the prediction[x] = probablity(f(x))\n",
    "    '''\n",
    "    possible_outcomes = list(task_mapping.values())\n",
    "    return logits[:,possible_outcomes] # looks only on relevant answers. index for answer is actually according to the query\n",
    "\n",
    "task = identity_task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9213f69d-82de-487e-b4b8-4f96b5ebed4a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Prompt-Tuning (Task) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b15bc17-e4b3-4490-ba65-e7352c7d4fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW([model.transformer.wte.learned_embedding], lr=1e-3)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "n_epochs = 10\n",
    "loss_f = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d309a653-aadb-4325-b934-c67a36401124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:09<00:00, 11.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 548.6201276779175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 12.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 273.1594034433365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 159.80558349192142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 84.80769973248243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 49.02762904390693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 32.34241774119437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 23.49921423010528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 12.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 18.250906142406166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 14.847236903384328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 12.488434534985572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "total_loss = []\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0\n",
    "    for query in tqdm(dataset):\n",
    "        # formatted_query, formatted_answer = format_query(query), torch.LongTensor([query])\n",
    "        formatted_query, formatted_answer = format_query(query), torch.LongTensor([task[query]])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # preds = only_relevant_logits(run_model(formatted_query), task).reshape(1, -1)\n",
    "        preds = run_model(model, tokenizer, formatted_query).reshape(1, -1)\n",
    "        loss = loss_f(preds, formatted_answer)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    scheduler.step()\n",
    "    print(\"Epoch Loss:\", epoch_loss)\n",
    "    total_loss.append(epoch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67397d9f-97e9-48cb-a11b-15aa5761c385",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Prompt-Tuning Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b7918b4-3cbd-4e7c-87b6-37c752912aae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:13<00:00, 37.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Accuracy: 99.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corrects = 0\n",
    "for query in tqdm(evalset):\n",
    "    # preds = only_relevant_logits(run_model(format_query(query)), task).reshape(1, -1)\n",
    "    preds = run_model(model, tokenizer, format_query(query)).reshape(1, -1)\n",
    "    # corrects += int(query == torch.argmax(preds))\n",
    "    f = int(task[query] == torch.argmax(preds))\n",
    "    corrects += f\n",
    "    \n",
    "print(f\"Task Accuracy: {100*corrects / len(evalset):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6895bbb5-4f01-4e9e-83d4-e1bf9f5ae72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1686053c0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158dbc34-5f83-4dd9-8b15-f9e25cb49b07",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Store Task Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa13b956-9943-49ee-93cf-4e2b0f879462",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = Path(\"promptmanteau_tokens\")\n",
    "dir_.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e233451-1a0b-4e47-ab29-bffaac5bde90",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_token_path = dir_ / \"identity_token3.pth\"\n",
    "torch.save(model.get_input_embeddings().learned_embedding, task_token_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c983763f-6826-422f-8fc5-e041ad6bfe60",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Analysis of Task-Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75bf7d1a-8341-43cb-b3e5-f6ca74d5ace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "token01 = torch.load(dir_ / \"identity_token1.pth\").detach()\n",
    "token02 = torch.load(dir_ / \"identity_token2.pth\").detach()\n",
    "\n",
    "token11 = torch.load(dir_ / \"add1_token1.pth\").detach()\n",
    "token12 = torch.load(dir_ / \"add1_token2.pth\").detach()\n",
    "token13 = torch.load(dir_ / \"add1_token3.pth\").detach()\n",
    "token14 = torch.load(dir_ / \"add1_token4.pth\").detach()\n",
    "\n",
    "token21 = torch.load(dir_ / \"add2_token1.pth\").detach()\n",
    "token22 = torch.load(dir_ / \"add2_token2.pth\").detach()\n",
    "token23 = torch.load(dir_ / \"add2_token3.pth\").detach()\n",
    "\n",
    "tokens = [token01, token02]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99f9cbec-a7f4-4183-ac77-3ee1e25cb79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_coeffs_for_convex_sum(n):\n",
    "    nums = np.random.rand(n)\n",
    "    return nums / sum(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2de37fe9-4220-4a7c-a080-1f36aae7a31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similiarity <0,1> = 0.0889\n"
     ]
    }
   ],
   "source": [
    "for i, j in itertools.combinations(range(len(tokens)), 2):\n",
    "    first_token = tokens[i]\n",
    "    second_token = tokens[j]\n",
    "    cos_sim = F.cosine_similarity(first_token, second_token).item()\n",
    "    print(f\"cosine similiarity <{i},{j}> = {cos_sim:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e8fa499-2d84-4025-be9d-e47b6554492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(modified_model, tokenizer, query, n_tokens, **kwargs):\n",
    "    padding = \"<|endoftext|>\" * n_tokens \n",
    "    text_to_encode = padding + query\n",
    "    encoding = tokenizer.encode(text_to_encode, return_tensors=\"pt\")\n",
    "    result = modified_model.generate(encoding, **kwargs)[0]\n",
    "    result = result[n_tokens:]\n",
    "    decoded_result = tokenizer.decode(result)\n",
    "    \n",
    "    return [decoded_result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a0508c1-0adf-4e9e-ae4b-113bd615e2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_model(model, task_tokens):\n",
    "    assert hasattr(model.get_input_embeddings(), \"learned_embedding\"), \"Model had to be constructed using SoftEmbedding class\"\n",
    "    model2 = deepcopy(model)\n",
    "    model2.get_input_embeddings().learned_embedding = nn.Parameter(torch.cat(task_tokens).detach())\n",
    "    return model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b5b9b3b-4368-46b9-afd1-eb61cc439ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coeffs_list: [1, 1]\n",
      "\tinput: 122,\n",
      "\tgenerate: '122,11.'\n",
      "--------------------------------------------------------------------------------\n",
      "\tinput: 36,\n",
      "\tgenerate: '36,null.'\n",
      "--------------------------------------------------------------------------------\n",
      "\tinput: 7,\n",
      "\tgenerate: '7,7.'\n",
      "--------------------------------------------------------------------------------\n",
      "\tinput: 1,\n",
      "\tgenerate: '1,{.'\n",
      "--------------------------------------------------------------------------------\n",
      "\tinput: 2,\n",
      "\tgenerate: '2,2.'\n",
      "--------------------------------------------------------------------------------\n",
      "\tinput: 13,\n",
      "\tgenerate: '13,11.'\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "prompts = [\"122,\",\n",
    "           \"36,\",\n",
    "          \"7,\",\n",
    "          \"1,\",\n",
    "          \"2,\",\n",
    "          \"13,\",]\n",
    "\n",
    "for i in range(1):\n",
    "    coeffs = generate_random_coeffs_for_convex_sum(len(tokens))\n",
    "    coeffs = [1,1]\n",
    "    print(\"coeffs_list:\", coeffs)\n",
    "    convex_comb_token = torch.tensor(coeffs).float() @ torch.cat(tokens) # some hacks for the case of list of size 1\n",
    "    task_tokens = [convex_comb_token] # we only have one token in this analysis\n",
    "    for prompt in prompts:\n",
    "        \n",
    "        print(f\"\\tinput: {prompt}\")  \n",
    "        model2 = modify_model(model, task_tokens)\n",
    "        decoded = generate_text(model2, tokenizer, prompt, n_tokens=len(task_tokens), max_new_tokens=2, pad_token_id=tokenizer.eos_token_id)\n",
    "        for output in decoded:\n",
    "            print(f\"\\tgenerate: {repr(output)}\")\n",
    "\n",
    "        print(\"-\" * 80)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ecfdf7-2bb7-4cc7-885b-9d1c81a4a986",
   "metadata": {},
   "source": [
    "### evaluation of the convex sum TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d105d313-5a08-4eab-91f7-79aae550d747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:13<00:00, 38.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Accuracy: 94.00%\n",
      "[0.66746926 0.33253074]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corrects = 0\n",
    "\n",
    "tokens = [token01, token02]\n",
    "coeffs = generate_random_coeffs_for_convex_sum(len(tokens))\n",
    "\n",
    "convex_comb_token = torch.tensor(coeffs).float() @ torch.cat(tokens)\n",
    "task_tokens = [convex_comb_token]\n",
    "\n",
    "model2 = modify_model(model, task_tokens)\n",
    "for query in tqdm(evalset):\n",
    "    # preds = only_relevant_logits(run_model(format_query(query)), task).reshape(1, -1)\n",
    "    preds = run_model(model2, tokenizer, format_query(query)).reshape(1, -1)\n",
    "    # corrects += int(query == torch.argmax(preds))\n",
    "    f = int(task[query] == torch.argmax(preds))\n",
    "    corrects += f\n",
    "    \n",
    "print(f\"Task Accuracy: {100*corrects / len(evalset):.2f}%\")\n",
    "print(coeffs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local",
   "language": "python",
   "name": "local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
